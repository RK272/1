{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPuMniW47rPuFQTvCFNROOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RK272/1/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iEvWFod7uAo",
        "outputId": "673b0b84-47bb-483e-f83e-64cc2bd3e41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is 1 GPU(s) available.\n",
            "we will use the gpu: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  print(\"there is %d GPU(s) available.\" % torch.cuda.device_count())\n",
        "  print(\"we will use the gpu:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"no gpu available using cpu instead\")\n",
        "    device=torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "XA4NvhtfpoFJ",
        "outputId": "c9da8945-ea6e-4a1d-c8f5-3ad5518494ef"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-83cbca59-4ae2-4824-93f9-cadbe38bafc9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-83cbca59-4ae2-4824-93f9-cadbe38bafc9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spam.csv to spam (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"spam.csv\")"
      ],
      "metadata": {
        "id": "e9gFQMJJOz8Z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7UAeh0Thp95-",
        "outputId": "d4ec52ae-972e-4bef-d1e3-330b1d91a617"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   A          c  label\n",
              "0  Text & meet someone sexy today. U can find a d...  need_help      0\n",
              "1  Free entry in 2 a wkly comp to win FA Cup fina...   Greeting      1\n",
              "2  FreeMsg Hey there darling it's been 3 week's n...     Ggreat      2\n",
              "3  WINNER!! As a valued network customer you have...  need_help      0\n",
              "4  Had your mobile 11 months or more? U R entitle...   Greeting      1\n",
              "5  SIX chances to win CASH! From 100 to 20,000 po...     Ggreat      2\n",
              "6  URGENT! You have won a 1 week FREE membership ...  need_help      0\n",
              "7  XXXMobileMovieClub: To use your credit, click ...   Greeting      1\n",
              "8  England v Macedonia - dont miss the goals/team...     Ggreat      2\n",
              "9  Thanks for your subscription to Ringtone UK yo...     Ggreat      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e51e2f38-ce1a-4da5-aebf-eda29d0e9519\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>c</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Text &amp; meet someone sexy today. U can find a d...</td>\n",
              "      <td>need_help</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>Greeting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>Ggreat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>need_help</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>Greeting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
              "      <td>Ggreat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
              "      <td>need_help</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
              "      <td>Greeting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
              "      <td>Ggreat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Thanks for your subscription to Ringtone UK yo...</td>\n",
              "      <td>Ggreat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e51e2f38-ce1a-4da5-aebf-eda29d0e9519')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e51e2f38-ce1a-4da5-aebf-eda29d0e9519 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e51e2f38-ce1a-4da5-aebf-eda29d0e9519');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f4f88e38-ce7e-4cfd-99ab-cfeb8722eb0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4f88e38-ce7e-4cfd-99ab-cfeb8722eb0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f4f88e38-ce7e-4cfd-99ab-cfeb8722eb0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_seWG1m-zkR",
        "outputId": "203430f3-eeb2-47ec-a41b-084c278c9f9c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['A', 'c', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIu0vuDb-ztg",
        "outputId": "d1f8fd3d-7972-4442-85e3-ab6e21c179de"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    1\n",
              "2    2\n",
              "3    0\n",
              "4    1\n",
              "5    2\n",
              "6    0\n",
              "7    1\n",
              "8    2\n",
              "9    2\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=df.A.values"
      ],
      "metadata": {
        "id": "ezQ4QeCfCU2m"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=df.label.values"
      ],
      "metadata": {
        "id": "hoP2j2OECVKv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YIoYvkVChgV",
        "outputId": "801b7a95-c509-49be-e31a-6c6efc3968b6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Text & meet someone sexy today. U can find a date or even flirt its up to U. Join 4 just 10p. REPLY with NAME & AGE eg Sam 25. 18 -msg recd@thirtyeight pence',\n",
              "       \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              "       \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\",\n",
              "       'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',\n",
              "       'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030',\n",
              "       'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info',\n",
              "       'URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18',\n",
              "       'XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL',\n",
              "       'England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+',\n",
              "       'Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orpaTaDrChtc",
        "outputId": "561cd9a1-9361-493e-ad88-5dcbfeb91405"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwTacUQzDIGA",
        "outputId": "59db36dd-9791-4ed9-ed1b-77e63b0c3732"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer"
      ],
      "metadata": {
        "id": "mCEwSf7QDfcx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AlbertTokenizer.from_pretrained('albert-base-v2',do_lower_case=True)"
      ],
      "metadata": {
        "id": "W_gnU4RkDgCv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=0\n",
        "for sent in sentences:\n",
        "  input_ids=tokenizer.encode(sent,add_special_tokens=True)\n",
        "  print(input_ids)\n",
        "  max_len=max(max_len,len(input_ids))\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNhYOf3BEbIx",
        "outputId": "59630cf6-1a00-45a1-ccd4-104c3c536aa6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 1854, 279, 1255, 737, 7819, 786, 9, 287, 92, 477, 21, 1231, 54, 166, 18265, 82, 71, 20, 287, 9, 1865, 268, 114, 332, 306, 9, 6504, 29, 204, 279, 348, 12369, 1113, 771, 9, 474, 13, 8, 79, 18, 263, 6042, 43, 1, 23582, 7748, 351, 2940, 3]\n",
            "[2, 551, 2792, 19, 172, 21, 619, 197, 102, 6479, 20, 628, 1399, 480, 426, 13, 38, 197, 38, 18, 852, 384, 123, 812, 9, 1854, 1399, 20, 10271, 12586, 20, 2588, 2792, 1301, 5, 384, 43, 20225, 38, 1684, 6, 38, 1569, 150, 22, 18, 5645, 13, 3099, 2520, 2714, 4031, 3283, 2549, 1087, 22, 18, 3]\n",
            "[2, 551, 79, 18, 263, 8409, 80, 9916, 32, 22, 18, 74, 203, 877, 22, 18, 130, 17, 90, 833, 97, 187, 31, 22, 43, 101, 109, 2414, 42, 71, 26, 32, 174, 60, 13, 11872, 5854, 187, 13, 13290, 354, 43, 6193, 5447, 20, 2660, 15, 13, 11, 165, 9, 2290, 20, 761, 12732, 3]\n",
            "[2, 1681, 19015, 28, 21, 13846, 982, 7705, 42, 57, 74, 1704, 20, 2588, 58, 13, 11, 10289, 1507, 7879, 187, 20, 2632, 645, 13, 2545, 3370, 16266, 13948, 165, 9, 2632, 1797, 13, 11234, 24474, 9, 7394, 390, 974, 104, 9, 3]\n",
            "[2, 41, 154, 3241, 547, 818, 54, 91, 60, 287, 761, 3146, 20, 11100, 20, 14, 5736, 4609, 3241, 18, 29, 3336, 26, 551, 187, 645, 14, 3241, 11100, 326, 551, 27, 713, 8464, 2738, 26713, 1762, 3]\n",
            "[2, 490, 11285, 20, 628, 3392, 187, 37, 808, 20, 11047, 6096, 20225, 38, 1, 272, 1635, 1306, 17, 2660, 20, 13, 24964, 3283, 9, 1516, 4354, 306, 118, 1185, 15, 400, 1185, 18, 15, 347, 2430, 13, 38, 18, 290, 6824, 5645, 6504, 13, 3712, 268, 15404, 3]\n",
            "[2, 15639, 187, 42, 57, 230, 21, 137, 877, 551, 4363, 19, 318, 13, 11, 29648, 1507, 1040, 4296, 187, 20225, 38, 14, 833, 45, 2632, 20, 90, 45, 13, 20219, 1036, 13, 38, 1569, 150, 13, 6483, 9, 43, 12665, 9, 2328, 13, 6109, 5316, 38, 43, 2353, 5309, 268, 25821, 6252, 103, 499, 165, 58, 465, 20393, 1087, 3]\n",
            "[2, 13, 13290, 12571, 22607, 16854, 45, 20, 275, 154, 3251, 15, 10840, 14, 3142, 306, 3508, 19, 14, 328, 20225, 38, 2802, 54, 10840, 235, 1, 7775, 6903, 1608, 306, 9, 13, 13290, 12571, 22607, 16854, 9, 960, 60, 103, 3726, 1251, 16455, 263, 6872, 17419, 10362, 6287, 3]\n",
            "[2, 648, 566, 12589, 13, 8, 1049, 1501, 14, 1547, 118, 6575, 996, 9, 20225, 38, 13, 911, 152, 173, 20, 13, 24649, 4536, 12369, 648, 20, 13, 24649, 4536, 1131, 45, 22424, 18, 15, 2207, 268, 38, 396, 38, 118, 291, 165, 9, 1323, 2353, 5309, 6326, 19230, 3277, 499, 2520, 499, 1251, 347, 2430, 3]\n",
            "[2, 3669, 26, 154, 14213, 20, 1765, 7117, 1063, 154, 3241, 129, 44, 4029, 13, 11, 10551, 6444, 2247, 10265, 34, 6504, 68, 1643, 54, 90, 9, 100, 42, 6504, 90, 42, 129, 52, 44, 4029, 3]\n",
            "61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "SzKfEYtoIAff"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids=[]\n",
        "attention_masks=[]\n",
        "for sent in sentences:\n",
        "  encoded_dict=tokenizer.encode_plus(sent,add_special_tokens=True,max_length=100,pad_to_max_length=True,return_attention_mask=True,return_tensors='pt',truncation=True)\n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "input_ids=torch.cat(input_ids,dim=0)\n",
        "attention_masks=torch.cat(attention_masks,dim=0)\n",
        "labels=torch.tensor(labels)\n",
        "print('original:',sentences[0])\n",
        "print('Token_IDs:',input_ids[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QkIFNpiEbVN",
        "outputId": "fd9cef1c-247b-4342-a6ae-71a97d3b618a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original: Text & meet someone sexy today. U can find a date or even flirt its up to U. Join 4 just 10p. REPLY with NAME & AGE eg Sam 25. 18 -msg recd@thirtyeight pence\n",
            "Token_IDs: tensor([    2,  1854,   279,  1255,   737,  7819,   786,     9,   287,    92,\n",
            "          477,    21,  1231,    54,   166, 18265,    82,    71,    20,   287,\n",
            "            9,  1865,   268,   114,   332,   306,     9,  6504,    29,   204,\n",
            "          279,   348, 12369,  1113,   771,     9,   474,    13,     8,    79,\n",
            "           18,   263,  6042,    43,     1, 23582,  7748,   351,  2940,     3,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apXU9bsmI0Ig",
        "outputId": "64150bae-d268-4d10-9c66-dc34b9e29c59"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfkoWOc6I5CY",
        "outputId": "cc357021-0a7a-41d8-bf8d-63ec4fd6aa01"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,  1854,   279,  1255,   737,  7819,   786,     9,   287,    92,\n",
              "          477,    21,  1231,    54,   166, 18265,    82,    71,    20,   287,\n",
              "            9,  1865,   268,   114,   332,   306,     9,  6504,    29,   204,\n",
              "          279,   348, 12369,  1113,   771,     9,   474,    13,     8,    79,\n",
              "           18,   263,  6042,    43,     1, 23582,  7748,   351,  2940,     3,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset,random_split\n",
        "dataset=TensorDataset(input_ids,attention_masks,labels)\n",
        "train_size=int(0.9*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "train_dataset,val_dataset=random_split(dataset,[train_size,val_size])\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuQ0rzruJB_f",
        "outputId": "b9e84017-de89-428b-9390-20fee0dd03bb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    9 training samples\n",
            "    1 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
        "batch_size=32\n",
        "train_dataloader=DataLoader(train_dataset,sampler=RandomSampler(train_dataset),batch_size=batch_size)\n",
        "validation_dataloader=DataLoader(\n",
        "    val_dataset,\n",
        "    sampler=SequentialSampler(val_dataset),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "tu-V6DRjKajB"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertForSequenceClassification,AdamW,AlbertConfig\n",
        "model=AlbertForSequenceClassification.from_pretrained(\n",
        "    \"albert-large-v2\",\n",
        "    num_labels=3,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        "    return_dict=False\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsdcnjdFMVTK",
        "outputId": "522a4e97-ea77-4941-e5e9-6f0d66cf94f7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForSequenceClassification(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=1024, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (attention_dropout): Dropout(p=0, inplace=False)\n",
              "                (output_dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (ffn_output): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (activation): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params=list(model.named_parameters())\n"
      ],
      "metadata": {
        "id": "HTKCxQF6Ka6L"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=AdamW(model.parameters(),lr=2e-5,eps=1e-8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI5m3AzO4GrK",
        "outputId": "40f5889b-4fc2-4584-ff0d-a45b06b554bf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs=40\n",
        "total_steps=len(train_dataloader)*epochs\n",
        "scheduler=get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "zsbslEjv5h8O"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def flat_accuracy(preds,labels):\n",
        "  pred_flat=np.argmax(preds,axis=1).flatten()\n",
        "  labels_flat=labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "metadata": {
        "id": "DYD9Bs7p6iJ_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded=int(round((elapsed)))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "5wvtkDaO7Ouw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ny0m75pc72dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "seed_val=42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "training_stats=[]\n",
        "total_t0=time.time()\n",
        "for epoch_i in range (0,epochs):\n",
        "  #lgdkskjsks\n",
        "  t0=time.time()\n",
        "  total_train_loss=0\n",
        "  model.train()\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    #gddkd\n",
        "    if step % 40 == 0 and not step==0:\n",
        "      elapsed=format_time(time.time()-t0)\n",
        "    b_input_ids=batch[0].to(device)\n",
        "    b_input_mask=batch[1].to(device)\n",
        "    b_labels=batch[2].to(device)\n",
        "    model.zero_grad()\n",
        "    loss,logits=model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)\n",
        "    total_train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "avg_train_loss=total_train_loss/len(train_dataloader)\n",
        "training_time= format_time(time.time() -t0)\n",
        "t0=time.time()\n",
        "model.eval()\n",
        "total_eval_accuracy=0\n",
        "total_eval_loss=0\n",
        "nb_eval_steps=0\n",
        "for batch in validation_dataloader:\n",
        "  b_input_ids=batch[0].to(device)\n",
        "  b_input_mask=batch[1].to(device)\n",
        "  b_labels=batch[2].to(device)\n",
        "  with torch.no_grad():\n",
        "    (loss,logits)=model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)\n",
        "  total_eval_loss +=loss.item()\n",
        "  logits=logits.detach().cpu().numpy()\n",
        "  label_ids=b_labels.to('cpu').numpy()\n",
        "  total_eval_accuracy += flat_accuracy(logits,label_ids)\n",
        "avg_val_accuracy=total_eval_accuracy/len(validation_dataloader)\n",
        "avg_val_loss=total_eval_loss/len(validation_dataloader)\n",
        "validation_time=format_time(time.time()- t0)\n",
        "print(\"accuracy:{0:2f}\".format(avg_val_accuracy))\n",
        "training_stats.append(\n",
        "    {\n",
        "        'epoch':epoch_i+1,\n",
        "        'trainingloss':avg_train_loss,\n",
        "        'valid_loss':avg_val_accuracy,\n",
        "        'valid acc':avg_val_accuracy,\n",
        "        'training time':training_time,\n",
        "        'validation time':validation_time\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiCmnywz72pz",
        "outputId": "f2e66d04-df23-4e75-c656-165d0c67cc85"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oObcj7oT72tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4zHfQdg1JuNZ"
      }
    }
  ]
}